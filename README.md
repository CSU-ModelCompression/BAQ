# BAQ

Bit Allocation Quantization

---

## (Introduction)

简要介绍你在做什么，比如：

本项目旨在提供对大语言模型（LLMs）进行高效压缩的工具，包括权重量化、剪枝、蒸馏等模块，帮助模型在资源受限设备上部署运行。

---
